{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without context, no text from story with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_openai_format = []\n",
    "message = f\"query: who welcomed Elara?\"\n",
    "    \n",
    "history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages= history_openai_format,\n",
    "temperature=0.2,\n",
    "seed=1000,\n",
    "stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It seems like you're asking about a specific event or context involving someone named Elara. However, without additional details, it's difficult to provide a precise answer. Could you please provide more context or specify which Elara you are referring to?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With context, first two chapters from the story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''### Title: **The Quantum Navigator**\n",
    "\n",
    "#### Chapter 1: The Discovery\n",
    "\n",
    "In the year 2075, the world was a tapestry of advanced technologies and interconnected systems. Cities floated above the clouds, and artificial intelligence governed almost every aspect of human life. Amidst this technological utopia, in a modest laboratory in the heart of New Tokyo, Dr. Elara Hoshino was on the verge of a groundbreaking discovery.\n",
    "\n",
    "Dr. Hoshino was a quantum physicist, a genius whose work had already revolutionized the field of quantum mechanics. Her current project was a mysterious device she called the \"Quantum Navigator.\" It was designed to manipulate the fabric of spacetime, allowing instantaneous travel between any two points in the universe. The concept was theoretical, but Elara had spent years perfecting the mathematics and technology behind it.\n",
    "\n",
    "On a foggy evening, as Elara meticulously calibrated the Navigator, a soft hum filled the room. The air around the device shimmered, and a swirling vortex of light appeared. Her heart raced as she realized the Navigator was operational. She cautiously approached the vortex, a mixture of fear and exhilaration coursing through her veins. With a deep breath, she stepped into the light.\n",
    "\n",
    "#### Chapter 2: The Other Side\n",
    "\n",
    "Elara emerged on the other side, not in a distant part of Earth but on a completely different planet. She found herself in a lush, alien jungle, with towering trees that glowed faintly in the twilight. The air was thick with the scent of unknown flora, and the sky was a deep indigo, dotted with unfamiliar constellations.\n",
    "\n",
    "As she marveled at the beauty of this alien world, she noticed movement in the underbrush. A group of tall, slender beings with translucent skin and luminescent eyes emerged. They communicated through a series of melodic tones, which Elara's universal translator quickly deciphered. The beings were the Lumarians, an ancient race with a deep understanding of the cosmos.\n",
    "\n",
    "The Lumarians welcomed Elara, intrigued by her arrival. They revealed that they had been aware of Earth's existence for millennia but had chosen to observe from afar. The Lumarians were peaceful and possessed advanced knowledge of quantum travel. They had long ago developed their own version of the Quantum Navigator, which they used to explore the universe and gather knowledge.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_openai_format = []\n",
    "message = f\"context: {context}, query: who welcomed Elara?\"\n",
    "    \n",
    "history_openai_format.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "response = client.chat.completions.create(model='gpt-4o-mini',\n",
    "messages= history_openai_format,\n",
    "temperature=0.2,\n",
    "seed=1000,\n",
    "stream=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Lumarians welcomed Elara when she arrived on their planet.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_context = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('story.txt', 'r') as file:\n",
    "    for f in file.readlines():\n",
    "        if f != '\\n' and f != '\\r':\n",
    "            all_s = f.split('. ')\n",
    "            all_context.extend(all_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The air around the device shimmered, and a swirling vortex of light appeared'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_context[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[-0.0473,  0.0227,  0.0392,  ...,  0.0192, -0.0031,  0.0206],\n",
      "        [-0.0824,  0.0418,  0.0520,  ..., -0.0407, -0.0298, -0.0191],\n",
      "        [-0.0679,  0.0118, -0.0084,  ..., -0.0755, -0.0538,  0.0421],\n",
      "        ...,\n",
      "        [-0.0440,  0.0123,  0.0182,  ..., -0.0137, -0.0519, -0.0059],\n",
      "        [ 0.0016, -0.1037,  0.0279,  ...,  0.0429, -0.0274,  0.0180],\n",
      "        [ 0.0263, -0.0158, -0.0072,  ...,  0.0951, -0.0298,  0.0023]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "# sentences = ['This is an example sentence', 'Each sentence is converted', context, context]\n",
    "sentences = all_context\n",
    "sentences.append(\"who welcomed Elara?\")\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2').to('cuda')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input.to('cuda'))\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([74, 384])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vector_a, vector_b):\n",
    "    # Calculate the dot product of the vectors\n",
    "    dot_product = np.dot(vector_a, vector_b)\n",
    "    \n",
    "    # Calculate the norm (magnitude) of each vector\n",
    "    norm_a = np.linalg.norm(vector_a)\n",
    "    norm_b = np.linalg.norm(vector_b)\n",
    "    \n",
    "    # Compute the cosine similarity\n",
    "    similarity = dot_product / (norm_a * norm_b)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elara confronted him, a fierce determination in her eyes'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_scores_map = {}\n",
    "for i in range(len(sentences)):\n",
    "    score = cosine_similarity(sentence_embeddings[-1].cpu().detach().numpy().reshape(1,-1), sentence_embeddings[i].cpu().detach().numpy())\n",
    "    index_scores_map[i] = float(score[0])\n",
    "    # print(f'index: {i}, score: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.01538220513612032,\n",
       " 1: 0.139244943857193,\n",
       " 2: 0.03870378062129021,\n",
       " 3: -0.009805893525481224,\n",
       " 4: 0.011766266077756882,\n",
       " 5: 0.3860347867012024,\n",
       " 6: 0.026740487664937973,\n",
       " 7: -0.005041817668825388,\n",
       " 8: 0.09352340549230576,\n",
       " 9: 0.47478488087654114,\n",
       " 10: 0.30354538559913635,\n",
       " 11: 0.041404251009225845,\n",
       " 12: 0.24035179615020752,\n",
       " 13: 0.13692905008792877,\n",
       " 14: 0.19120171666145325,\n",
       " 15: 0.1336517632007599,\n",
       " 16: 0.5801576375961304,\n",
       " 17: 0.1877894252538681,\n",
       " 18: 0.19359081983566284,\n",
       " 19: 0.11199590563774109,\n",
       " 20: 0.126316636800766,\n",
       " 21: 0.4495638906955719,\n",
       " 22: 0.23690766096115112,\n",
       " 23: 0.7066745758056641,\n",
       " 24: 0.22464434802532196,\n",
       " 25: 0.26562198996543884,\n",
       " 26: 0.15418359637260437,\n",
       " 27: 0.2914455831050873,\n",
       " 28: 0.45764461159706116,\n",
       " 29: 0.2436717450618744,\n",
       " 30: 0.17598803341388702,\n",
       " 31: 0.5322508215904236,\n",
       " 32: 0.29709339141845703,\n",
       " 33: 0.0661139190196991,\n",
       " 34: 0.5166687369346619,\n",
       " 35: 0.5700124502182007,\n",
       " 36: 0.3175065815448761,\n",
       " 37: 0.16544167697429657,\n",
       " 38: 0.5682152509689331,\n",
       " 39: 0.1326185017824173,\n",
       " 40: 0.10398561507463455,\n",
       " 41: 0.09640709310770035,\n",
       " 42: 0.6106914281845093,\n",
       " 43: 0.008578523993492126,\n",
       " 44: 0.6151676177978516,\n",
       " 45: 0.26564663648605347,\n",
       " 46: 0.1448679268360138,\n",
       " 47: 0.37479284405708313,\n",
       " 48: 0.2280796319246292,\n",
       " 49: 0.07469067722558975,\n",
       " 50: 0.3178873658180237,\n",
       " 51: 0.18415428698062897,\n",
       " 52: 0.1197327971458435,\n",
       " 53: 0.3452325165271759,\n",
       " 54: 0.4974634349346161,\n",
       " 55: 0.12220466136932373,\n",
       " 56: 0.5697394609451294,\n",
       " 57: 0.0941874161362648,\n",
       " 58: 0.6471617221832275,\n",
       " 59: 0.19057711958885193,\n",
       " 60: 0.41857481002807617,\n",
       " 61: 0.4232420027256012,\n",
       " 62: 0.11674760282039642,\n",
       " 63: 0.1348610520362854,\n",
       " 64: 0.1548510044813156,\n",
       " 65: 0.4947519302368164,\n",
       " 66: 0.4616549015045166,\n",
       " 67: 0.6250523924827576,\n",
       " 68: 0.30800771713256836,\n",
       " 69: 0.2995515465736389,\n",
       " 70: 0.4310644268989563,\n",
       " 71: 0.1863589733839035,\n",
       " 72: 0.5733211040496826,\n",
       " 73: 1.0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  index_scores_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by values in descending order\n",
    "sorted_dict_desc = dict(sorted(index_scores_map.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_info = []\n",
    "for top in list(sorted_dict_desc.keys())[:5]:\n",
    "    relevant_info.append(sentences[top])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who welcomed Elara?',\n",
       " 'The Lumarians welcomed Elara, intrigued by her arrival',\n",
       " 'Elara confronted him, a fierce determination in her eyes',\n",
       " 'Elara decided to remain on Luminaria, continuing her research and learning from the Lumarians',\n",
       " 'Yet, with each obstacle, Elara grew more determined']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4045593"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sentence_embeddings[0].cpu().detach().numpy(), sentence_embeddings[1].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008613202"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sentence_embeddings[0].cpu().detach().numpy(), sentence_embeddings[2].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0075974776"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(sentence_embeddings[1].cpu().detach().numpy(), sentence_embeddings[2].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grading_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
